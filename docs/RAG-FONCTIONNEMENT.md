# üß† Comment fonctionne le RAG Server

> Une explication simple du fonctionnement m√©tier du serveur RAG pour la documentation Thomson MO5

## Le probl√®me de d√©part

Quand on d√©veloppe pour le Thomson MO5, on a besoin de consulter beaucoup de documentation :
- Les instructions du processeur 6809
- La cartographie m√©moire
- Les registres vid√©o
- Des exemples de code

Le probl√®me, c'est qu'on ne sait pas toujours **o√π** chercher exactement.

On se retrouve √† ouvrir 10 fichiers diff√©rents, √† faire des recherches par mots-cl√©s, √† esp√©rer tomber sur le bon passage...

**Et si on pouvait simplement poser une question et obtenir les passages pertinents ?**

C'est exactement ce que fait le RAG Server. üéØ

## L'id√©e g√©n√©rale

Le RAG Server, c'est comme avoir un **biblioth√©caire expert** qui conna√Æt toute la documentation par c≈ìur.

Vous lui posez une question :
> "Comment utiliser le registre X pour l'indexation ?"

Et il vous apporte directement les passages pertinents de la documentation, m√™me si vous n'avez pas utilis√© les mots exacts.

**Pas de recherche manuelle, pas de mots-cl√©s √† deviner.**

Le syst√®me comprend le **sens** de votre question et trouve les r√©ponses.

## Les concepts cl√©s (avant d'aller plus loin)

Avant de d√©tailler comment √ßa marche, il faut comprendre quelques termes.

Pas de panique, je vais expliquer simplement. üòâ

### RAG (Retrieval-Augmented Generation)

**RAG** = Recherche + G√©n√©ration augment√©e

En gros :
1. On **recherche** les passages pertinents dans la documentation
2. On les **fournit** √† une IA (comme ChatGPT) pour qu'elle g√©n√®re une r√©ponse

Dans notre cas, on s'occupe surtout de la partie **recherche**.

### Chunk (morceau)

Un **chunk**, c'est un morceau de texte d√©coup√© d'un document.

Pourquoi d√©couper ?
- Les documents sont trop longs pour √™tre trait√©s d'un coup
- On veut trouver **pr√©cis√©ment** le passage qui r√©pond √† la question
- Pas tout le document, juste la partie utile

**Exemple** :

Un document de 5000 caract√®res sera d√©coup√© en 5 chunks de ~1000 caract√®res chacun.

Chaque chunk = une "carte de visite" d'un concept.

### Embedding (empreinte num√©rique)

Un **embedding**, c'est une repr√©sentation num√©rique du **sens** d'un texte.

Concr√®tement, c'est un vecteur (une liste) de 384 nombres.

**Pourquoi faire √ßa ?**

Parce qu'on ne peut pas comparer du texte directement.

Comment savoir que "registre accumulateur" et "accumulator register" parlent de la m√™me chose ?

Avec les embeddings, on transforme le texte en nombres, et on peut calculer la **similarit√©** entre deux textes.

**Exemple** :

```
"registre accumulateur"     ‚Üí [0.5, 0.3, 0.1, ..., 0.2]
"accumulator register"      ‚Üí [0.52, 0.28, 0.12, ..., 0.19]  ‚Üê PROCHE !
"m√©moire vid√©o"             ‚Üí [-0.2, 0.8, -0.5, ..., 0.6]   ‚Üê LOIN
```

Les textes similaires ont des embeddings proches.

### TF-IDF (la technique d'embedding)

**TF-IDF** = Term Frequency - Inverse Document Frequency

C'est la technique qu'on utilise pour g√©n√©rer les embeddings.

En gros :
- **TF** (Term Frequency) : √Ä quelle fr√©quence un mot appara√Æt dans le texte ?
- **IDF** (Inverse Document Frequency) : Est-ce que ce mot est rare ou commun dans tous les documents ?

Un mot rare et pr√©sent dans le texte = important pour le sens.

**Avantage** : Tout est calcul√© **localement**, pas besoin d'appeler une API externe (OpenAI, etc.).

### Similarit√© cosinus

C'est la m√©thode pour comparer deux embeddings.

On calcule un **score de 0 √† 1** :
- **0** = compl√®tement diff√©rent
- **1** = identique

Plus le score est √©lev√©, plus les textes sont similaires.

### pgvector (la base de donn√©es vectorielle)

**pgvector** est une extension de PostgreSQL qui permet de stocker des vecteurs (embeddings).

Elle offre aussi des **index sp√©ciaux** (IVFFlat) pour faire des recherches vectorielles ultra-rapides.

Au lieu de comparer manuellement avec tous les chunks (lent), l'index permet de trouver rapidement les plus proches.

---

üí¨ **En r√©sum√©** : On d√©coupe les documents en chunks, on transforme chaque chunk en embedding (vecteur de nombres), et on stocke tout √ßa dans PostgreSQL avec pgvector. Quand on pose une question, on la transforme aussi en embedding, et on cherche les chunks les plus proches.

---

## Comment √ßa marche concr√®tement ?

Maintenant qu'on a les bases, voyons comment le syst√®me fonctionne au quotidien.

Il y a trois grandes √©tapes :
1. **Ingestion** : Remplir la base de connaissances
2. **Surveillance** : D√©tecter les changements
3. **Recherche** : R√©pondre aux questions

### √âtape 1 : Ingestion (remplir la biblioth√®que)

Au d√©marrage du serveur, il va lire tous les fichiers Markdown dans le dossier `/knowledge`.

**Voici ce qui se passe pour chaque fichier** :

#### 1.1 - Lecture du fichier

Le serveur lit le contenu du fichier.

Exemple : `guide-6809.md`

```markdown
# Motorola 6809 - Registres

Le processeur 6809 poss√®de plusieurs registres :
- A et B : registres accumulateurs 8 bits
- D : registre 16 bits (combinaison de A et B)
- X et Y : registres d'index 16 bits
- U et S : pointeurs de pile 16 bits
- PC : compteur de programme 16 bits

## Utilisation des registres

Le registre A est utilis√© pour...
```

#### 1.2 - D√©coupage en chunks

Le document est d√©coup√© en morceaux de ~1000 caract√®res.

**Strat√©gie de d√©coupage** :
- On respecte les sections Markdown (titres `#`, `##`, etc.)
- On √©vite de couper au milieu d'une phrase
- On ajoute un **chevauchement** de 200 caract√®res entre les chunks

**Pourquoi un chevauchement ?**

Pour ne pas perdre le contexte entre deux chunks.

Si un chunk se termine par "...le registre X est utilis√© pour", le chunk suivant commencera par "le registre X est utilis√© pour l'indexation...".

Comme √ßa, on ne coupe pas les concepts en deux.

**R√©sultat** :

```
üì¶ Chunk 0 : "# Motorola 6809 - Registres\n\nLe processeur 6809..."
üì¶ Chunk 1 : "## Utilisation des registres\n\nLe registre A..."
üì¶ Chunk 2 : "## Modes d'adressage\n\nLe 6809 supporte..."
...
```

Chaque chunk garde aussi des **m√©tadonn√©es** :
- Position dans le document (d√©but, fin)
- Titre de la section (`# Registres`)
- Nombre de tokens estim√©s
- Index du chunk (0, 1, 2, ...)

#### 1.3 - G√©n√©ration des embeddings

Pour chaque chunk, on g√©n√®re un **embedding** (vecteur de 384 nombres).

C'est fait avec **TF-IDF**, une technique locale (pas d'API externe).

**Comment √ßa marche ?**

1. On construit un **vocabulaire** √† partir de tous les documents
2. Pour chaque chunk, on calcule l'importance de chaque mot
3. On obtient un vecteur de 384 dimensions

**Exemple** :

```
Chunk : "Le registre A est un accumulateur 8 bits"
    ‚Üì
Embedding : [0.23, -0.45, 0.12, ..., 0.67]  (384 nombres)
```

#### 1.4 - Stockage dans PostgreSQL

Tout est stock√© dans la base de donn√©es PostgreSQL avec l'extension **pgvector**.

**Structure** :

```
üìä Table "Documents"
- Id : UUID unique
- FileName : "guide-6809.md"
- FilePath : "/knowledge/cpu/guide-6809.md"
- Title : "Guide du Motorola 6809"
- Content : texte complet du document
- ContentHash : empreinte du contenu (pour d√©tecter les modifications)
- CreatedAt, UpdatedAt : dates
- IsActive : true/false

üìä Table "DocumentChunks"
- Id : UUID unique
- DocumentId : lien vers le document parent
- ChunkIndex : 0, 1, 2, ...
- Content : "Le registre A est un accumulateur..."
- Embedding : vecteur de 384 dimensions ‚≠ê
- StartPosition, EndPosition : position dans le document
- SectionHeading : "# Registres"
- TokenCount : nombre de tokens estim√©s
- CreatedAt : date de cr√©ation
```

L'index **IVFFlat** sur la colonne `Embedding` permet de faire des recherches vectorielles ultra-rapides.

#### 1.5 - D√©tection des tags

Le syst√®me analyse le contenu du document et d√©tecte automatiquement des **tags**.

Exemples de tags : "CPU", "M√©moire", "Vid√©o", "Assembleur", etc.

Ces tags permettent de filtrer les r√©sultats de recherche plus tard.

**R√©sultat** :

```
üìÑ Document "guide-6809.md"
   ‚îú‚îÄ‚îÄ üè∑Ô∏è Tag "CPU"
   ‚îú‚îÄ‚îÄ üè∑Ô∏è Tag "Registres"
   ‚îî‚îÄ‚îÄ üè∑Ô∏è Tag "6809"
```

üí¨ **En r√©sum√©** : Pour chaque fichier, on lit le contenu, on d√©coupe en chunks, on g√©n√®re les embeddings, et on stocke tout dans PostgreSQL avec des tags.

---

### √âtape 2 : Surveillance (d√©tecter les changements)

Une fois l'ingestion initiale termin√©e, le serveur ne s'arr√™te pas l√†.

Il surveille en permanence le dossier `/knowledge` pour d√©tecter les changements.

**Comment √ßa marche ?**

Un **File Watcher** (surveillant de fichiers) observe le dossier.

D√®s qu'un fichier est cr√©√©, modifi√©, supprim√© ou renomm√©, il d√©clenche une action.

**Exemple** :

```
üìÅ /knowledge/cpu/guide-6809.md
    ‚Üì (vous modifiez le fichier)
üîî √âv√©nement "FileChanged" d√©tect√©
    ‚Üì
‚è±Ô∏è  Attente de 2 secondes (batch processing)
    ‚Üì
üîÑ R√©-indexation automatique du fichier
    ‚Üì
‚úÖ Base de donn√©es mise √† jour
```

**Pourquoi attendre 2 secondes ?**

Pour **grouper** les changements.

Si vous modifiez le fichier 10 fois en 2 secondes (sauvegarde automatique de l'√©diteur, par exemple), le syst√®me ne va pas r√©-indexer 10 fois.

Il attend que √ßa se calme, puis traite une seule fois.

**Optimisations** :
- **Batching** : Grouper les changements
- **D√©duplication** : Si le m√™me fichier change plusieurs fois, traiter une seule fois
- **Hash de contenu** : Ne r√©-indexer que si le contenu a vraiment chang√© (pas juste la date de modification)

üí¨ **En r√©sum√©** : Le serveur surveille le dossier `/knowledge` en permanence. D√®s qu'un fichier change, il le r√©-indexe automatiquement. Pas besoin de red√©marrer le serveur.

---

### √âtape 3 : Recherche (r√©pondre aux questions)

C'est l√† que la magie op√®re. üé©

Vous posez une question via l'API REST, et le syst√®me trouve les passages pertinents.

**Exemple de question** :

> "Comment utiliser le registre X pour l'indexation ?"

**Voici ce qui se passe** :

#### 3.1 - G√©n√©ration de l'embedding de la question

La question est transform√©e en embedding, exactement comme les chunks.

```
Question : "Comment utiliser le registre X pour l'indexation ?"
    ‚Üì
Embedding : [0.45, -0.23, 0.67, ..., 0.12]  (384 dimensions)
```

#### 3.2 - Recherche vectorielle

Le syst√®me compare l'embedding de la question avec **tous** les embeddings des chunks dans la base.

Il calcule la **similarit√© cosinus** entre la question et chaque chunk.

```
Comparaison avec tous les chunks :
- Chunk 1 : 0.92 ‚≠ê (tr√®s pertinent)
- Chunk 2 : 0.87 ‚≠ê (pertinent)
- Chunk 3 : 0.45 (peu pertinent)
- Chunk 4 : 0.12 (pas pertinent)
- ...
```

**Comment c'est rapide ?**

Gr√¢ce √† l'index **IVFFlat** de pgvector.

Au lieu de comparer avec tous les chunks un par un (lent), l'index permet de trouver rapidement les plus proches.

#### 3.3 - Filtrage (optionnel)

On peut filtrer les r√©sultats par **tags**.

Par exemple, si vous cherchez uniquement dans la documentation CPU :

```
Filtrer par tags : ["CPU", "Registres"]
```

Seuls les chunks des documents ayant ces tags seront consid√©r√©s.

On peut aussi filtrer par **document actif** (`IsActive = true`).

#### 3.4 - Tri et limitation

Les chunks sont tri√©s par **score de similarit√©** (du plus pertinent au moins pertinent).

On prend les **top N** r√©sultats (par exemple, les 5 meilleurs).

#### 3.5 - Retour des r√©sultats

Le syst√®me retourne un JSON avec les chunks les plus pertinents.

**Exemple de r√©ponse** :

```json
[
  {
    "content": "Le registre X est utilis√© pour l'indexation...",
    "score": 0.92,
    "documentTitle": "Guide du 6809",
    "sectionHeading": "Registres d'index",
    "tags": ["CPU", "Registres"]
  },
  {
    "content": "Exemple d'utilisation du registre X...",
    "score": 0.87,
    "documentTitle": "Exemples de code",
    "sectionHeading": "Indexation",
    "tags": ["CPU", "Exemples"]
  },
  ...
]
```

üí¨ **En r√©sum√©** : La question est transform√©e en embedding, compar√©e avec tous les chunks, et les plus pertinents sont retourn√©s. Tout √ßa en quelques millisecondes gr√¢ce √† l'index pgvector.



---

## Un exemple complet de bout en bout

Pour bien comprendre, voici un sc√©nario complet.

### Sc√©nario : J'ajoute un nouveau document

Vous venez d'√©crire un nouveau fichier de documentation sur l'affichage vid√©o du MO5.

Vous le copiez dans `/knowledge/video/ecran-mo5.md`.

**Voici ce qui se passe automatiquement** :

```
1Ô∏è‚É£ D√âTECTION
   üìÑ /knowledge/video/ecran-mo5.md (nouveau fichier)
       ‚Üì
   üîî File Watcher d√©tecte la cr√©ation

2Ô∏è‚É£ INGESTION
   üìñ Lecture du contenu (3500 caract√®res)
   ‚úÇÔ∏è  D√©coupage en 4 chunks de ~1000 caract√®res
   üßÆ G√©n√©ration de 4 embeddings (TF-IDF)
   üíæ Insertion dans PostgreSQL
       ‚Üì
   ‚úÖ 4 nouveaux chunks dans la base

3Ô∏è‚É£ D√âTECTION DE TAGS
   üè∑Ô∏è  Analyse du contenu
   üè∑Ô∏è  Tags d√©tect√©s : "Vid√©o", "√âcran", "M√©moire"
   üíæ Association Document ‚Üî Tags

4Ô∏è‚É£ MISE √Ä JOUR DU VOCABULAIRE
   üìö Mise √† jour du vocabulaire TF-IDF global
   üîÑ R√©g√©n√©ration de TOUS les embeddings
       ‚Üì
   ‚úÖ Base de donn√©es coh√©rente
```

**R√©sultat** : Votre nouveau document est imm√©diatement disponible pour la recherche.

Pas besoin de red√©marrer le serveur, pas de commande manuelle √† lancer.

### Sc√©nario : Je pose une question

Vous d√©veloppez un jeu et vous voulez afficher un pixel √† l'√©cran.

Vous posez la question √† l'API :

> "Comment afficher un pixel √† l'√©cran ?"

**Voici ce qui se passe** :

```
1Ô∏è‚É£ G√âN√âRATION EMBEDDING QUESTION
   "Comment afficher un pixel √† l'√©cran ?"
       ‚Üì
   [0.34, -0.56, 0.78, ..., 0.21]  (384 dimensions)

2Ô∏è‚É£ RECHERCHE VECTORIELLE
   üîç Comparaison avec tous les chunks (disons 150)
   üìä Calcul des scores de similarit√©
       ‚Üì
   R√©sultats tri√©s par score

3Ô∏è‚É£ TOP 5 R√âSULTATS
   ‚≠ê Chunk 42 (score: 0.94) - "Affichage pixel par pixel"
   ‚≠ê Chunk 15 (score: 0.89) - "M√©moire vid√©o du MO5"
   ‚≠ê Chunk 67 (score: 0.85) - "Modes graphiques"
   ‚≠ê Chunk 23 (score: 0.82) - "Palette de couleurs"
   ‚≠ê Chunk 91 (score: 0.78) - "Exemples de code graphique"

4Ô∏è‚É£ RETOUR √Ä L'UTILISATEUR
   üìÑ JSON avec les 5 chunks + m√©tadonn√©es
```

**R√©sultat** : Vous obtenez les 5 passages les plus pertinents de la documentation.

M√™me si vous n'avez pas utilis√© les mots exacts ("pixel", "affichage"), le syst√®me a compris le sens de votre question.

---

## Pourquoi c'est mieux qu'une recherche par mots-cl√©s ?

Vous vous demandez peut-√™tre : "Pourquoi ne pas juste faire une recherche par mots-cl√©s ?"

Bonne question. üòâ

**Avec une recherche par mots-cl√©s** :

Vous cherchez "registre accumulateur".

Le syst√®me trouve uniquement les documents contenant **exactement** ces mots.

Si un document parle de "accumulator register" (en anglais), il ne sera pas trouv√©.

Si un document parle de "registre A" sans mentionner "accumulateur", il ne sera pas trouv√© non plus.

**Avec une recherche s√©mantique (embeddings)** :

Vous cherchez "registre accumulateur".

Le syst√®me comprend le **sens** de votre question.

Il trouve :
- Les documents parlant de "accumulator register" (m√™me concept)
- Les documents parlant de "registre A" (c'est un accumulateur)
- Les documents parlant de "registres 8 bits" (contexte similaire)

**R√©sultat** : Vous trouvez beaucoup plus de r√©sultats pertinents, m√™me si les mots exacts ne sont pas pr√©sents.

---

## Les avantages du syst√®me

### ‚úÖ Recherche s√©mantique

Le syst√®me comprend le **sens**, pas juste les mots-cl√©s.

Vous pouvez poser des questions naturelles, comme si vous parliez √† quelqu'un.

### ‚úÖ Automatique

D√®s que vous ajoutez ou modifiez un fichier dans `/knowledge`, il est automatiquement index√©.

Pas besoin de red√©marrer le serveur, pas de commande manuelle.

### ‚úÖ Local

Tout est calcul√© **localement** avec TF-IDF.

Pas besoin d'appeler une API externe (OpenAI, etc.).

Pas de co√ªt, pas de d√©pendance, pas de probl√®me de confidentialit√©.

### ‚úÖ Rapide

Gr√¢ce √† l'index **IVFFlat** de pgvector, les recherches sont ultra-rapides.

M√™me avec des milliers de chunks, la r√©ponse arrive en quelques millisecondes.

### ‚úÖ √âvolutif

Vous pouvez ajouter autant de documents que vous voulez.

Le syst√®me s'adapte automatiquement.

---

## Configuration et maintenance

### Param√®tres ajustables

Vous pouvez configurer plusieurs param√®tres dans `appsettings.json` :

- **Taille des chunks** : 1000 caract√®res (d√©faut)
- **Overlap** : 200 caract√®res (d√©faut)
- **Nombre de r√©sultats** : configurable par requ√™te (ex: top 5, top 10)
- **Filtrage par tags** : optionnel

### Op√©rations courantes

**Ajouter un document** :
- Copiez le fichier Markdown dans `/knowledge`
- C'est tout ! Le syst√®me l'indexe automatiquement

**Modifier un document** :
- √âditez le fichier dans `/knowledge`
- Le syst√®me d√©tecte le changement et r√©-indexe automatiquement

**Supprimer un document** :
- Supprimez le fichier de `/knowledge`
- Le syst√®me marque le document comme inactif dans la base

**R√©initialiser compl√®tement** :
- Videz la base de donn√©es
- Red√©marrez le serveur
- L'ingestion initiale se relance automatiquement

---

## Cas d'usage concrets

Pour finir, voici quelques exemples de questions que vous pourriez poser au syst√®me.

### Cas 1 : D√©veloppeur d√©butant MO5

**Question** : "Comment initialiser le processeur 6809 ?"

**R√©sultats attendus** :
- Chunk 1 : "S√©quence de d√©marrage du 6809"
- Chunk 2 : "Initialisation des registres"
- Chunk 3 : "Vecteur de reset"
- Chunk 4 : "Exemple de code d'initialisation"

### Cas 2 : D√©veloppeur exp√©riment√©

**Question** : "Optimisation des acc√®s m√©moire en mode direct"

**R√©sultats attendus** :
- Chunk 1 : "Mode d'adressage direct vs √©tendu"
- Chunk 2 : "Performance des instructions"
- Chunk 3 : "Techniques d'optimisation"
- Chunk 4 : "Exemples de code optimis√©"

### Cas 3 : Documentation technique

**Question** : "Registres du contr√¥leur vid√©o"

**R√©sultats attendus** :
- Chunk 1 : "Cartographie m√©moire vid√©o"
- Chunk 2 : "Registres de configuration"
- Chunk 3 : "Modes graphiques disponibles"
- Chunk 4 : "Exemples de programmation vid√©o"

---

## R√©sum√©

Pour r√©sumer tout √ßa en quelques points :

### Le principe

Le RAG Server transforme la documentation en une base de connaissances **recherchable s√©mantiquement**.

Au lieu de chercher par mots-cl√©s, vous posez des questions naturelles et le syst√®me trouve les passages pertinents.

### Les 3 √©tapes

1. **Ingestion** : Les documents sont d√©coup√©s en chunks et transform√©s en embeddings
2. **Surveillance** : Les modifications de fichiers d√©clenchent une r√©-indexation automatique
3. **Recherche** : Les questions sont compar√©es aux chunks pour trouver les plus pertinents

### Les avantages

- ‚úÖ Recherche s√©mantique (comprend le sens)
- ‚úÖ Automatique (pas de commande manuelle)
- ‚úÖ Local (pas d'API externe)
- ‚úÖ Rapide (index pgvector)
- ‚úÖ √âvolutif (ajoutez autant de documents que vous voulez)

### L'utilisation

**Ajouter un document** : Copiez-le dans `/knowledge`

**Poser une question** : Appelez l'API REST

**Obtenir les r√©sultats** : Les chunks les plus pertinents vous sont retourn√©s

---

## Glossaire

Pour r√©f√©rence, voici les termes techniques utilis√©s dans ce document :

| Terme | D√©finition |
|-------|------------|
| **RAG** | Retrieval-Augmented Generation - Recherche + G√©n√©ration augment√©e |
| **Chunk** | Morceau de texte d√©coup√© d'un document (~1000 caract√®res) |
| **Embedding** | Vecteur num√©rique repr√©sentant le sens d'un texte (384 dimensions) |
| **TF-IDF** | Term Frequency - Inverse Document Frequency (technique d'embedding locale) |
| **pgvector** | Extension PostgreSQL pour stocker et rechercher des vecteurs |
| **Similarit√© cosinus** | Mesure de proximit√© entre deux vecteurs (score de 0 √† 1) |
| **IVFFlat** | Type d'index pour acc√©l√©rer les recherches vectorielles |
| **File Watcher** | Service qui surveille les modifications de fichiers |
| **Batch processing** | Traitement group√© des changements (optimisation) |
| **Overlap** | Chevauchement entre les chunks (200 caract√®res par d√©faut) |

---

üí¨ **En r√©sum√©** : Le RAG Server, c'est une biblioth√®que intelligente pour la documentation Thomson MO5. Vous posez une question, il trouve les passages pertinents. Simple, rapide, et tout en local. üöÄ

