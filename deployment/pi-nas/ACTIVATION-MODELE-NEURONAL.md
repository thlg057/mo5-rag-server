# ğŸ§  Activation du ModÃ¨le Neuronal (Sentence Transformers)

> Guide pour activer le modÃ¨le neuronal sur votre Raspberry Pi NAS

## ğŸ“‹ Ce qu'on va faire

Actuellement, le RAG Server utilise **TF-IDF** (formule mathÃ©matique simple).

On va passer Ã  **Sentence Transformers** (modÃ¨le neuronal) pour une meilleure qualitÃ© de recherche sÃ©mantique.

**Avantages** :
- âœ… Meilleure comprÃ©hension du sens des textes
- âœ… DÃ©tection des synonymes et paraphrases
- âœ… Recherche sÃ©mantique plus prÃ©cise

**InconvÃ©nients** :
- âŒ NÃ©cessite Python 3.8+
- âŒ ~500 MB d'espace disque pour le modÃ¨le
- âŒ Plus lent que TF-IDF (mais toujours rapide)

---

## ğŸ”§ Ã‰tape 1 : Installer Python sur le Raspberry Pi

### VÃ©rifier si Python est dÃ©jÃ  installÃ©

Connectez-vous en SSH Ã  votre Raspberry Pi :

```bash
ssh votre-user@votre-raspberry-pi
```

VÃ©rifiez la version de Python :

```bash
python3 --version
```

**Si vous voyez** : `Python 3.x.x` (avec x >= 8) â†’ **Parfait, passez Ã  l'Ã©tape 2 !**

**Si Python n'est pas installÃ© ou version < 3.8** â†’ Installez-le :

```bash
# Mettre Ã  jour les packages
sudo apt update

# Installer Python 3 et pip
sudo apt install -y python3 python3-pip python3-venv

# VÃ©rifier l'installation
python3 --version
pip3 --version
```

---

## ğŸ³ Ã‰tape 2 : Modifier le Dockerfile

Le Dockerfile actuel n'inclut pas Python. On va l'ajouter.

**Fichier** : `deployment/pi-nas/Dockerfile.arm64`

Vous avez deux options :

### Option A : Modifier le Dockerfile existant (recommandÃ©)

Je vais crÃ©er un nouveau Dockerfile avec Python inclus.

### Option B : Utiliser Python sur l'hÃ´te (plus simple mais moins isolÃ©)

Monter Python de l'hÃ´te dans le conteneur (voir Ã©tape 3).

---

## ğŸ“ Ã‰tape 3 : Modifier docker-compose.yml

**Fichier** : `deployment/pi-nas/docker-compose.yml`

### Changements Ã  faire

1. **Changer le provider** : `TfIdf` â†’ `Local`
2. **Ajouter la configuration Python**
3. **Monter Python dans le conteneur** (si option B)

### Configuration finale

```yaml
api:
  build:
    context: ../..
    dockerfile: deployment/pi-nas/Dockerfile.arm64
    target: runtime
  image: mo5-rag-api:latest
  container_name: mo5-rag-api
  ports:
    - "8080:8080"
  environment:
    - ASPNETCORE_ENVIRONMENT=Production
    - ASPNETCORE_URLS=http://+:8080
    - ConnectionStrings__DefaultConnection=Host=postgres;Database=mo5_rag;Username=mo5_user;Password=mo5_password_change_me;Include Error Detail=false
    # ğŸ”¥ CHANGEMENT ICI : TfIdf â†’ Local
    - EmbeddingService__Provider=Local
    - EmbeddingService__VectorDimensions=384
    # ğŸ”¥ NOUVEAU : Configuration Python
    - LocalEmbedding__ModelName=paraphrase-multilingual-MiniLM-L12-v2
    - LocalEmbedding__PythonPath=python3
    - RagSettings__KnowledgeBasePath=/app/knowledge
    - RagSettings__ChunkSize=1000
    - RagSettings__ChunkOverlap=200
    - RagSettings__MaxResults=10
    - RagSettings__MinSimilarityScore=0.7
  depends_on:
    postgres:
      condition: service_healthy
  volumes:
    - ../../knowledge:/app/knowledge:ro
  restart: unless-stopped
  networks:
    - mo5-rag-network
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 40s
```

---

## ğŸš€ Ã‰tape 4 : CrÃ©er le nouveau Dockerfile avec Python

Je vais crÃ©er un nouveau Dockerfile qui inclut Python et les dÃ©pendances nÃ©cessaires.

**Fichier** : `deployment/pi-nas/Dockerfile.arm64.neuronal`

---

## ğŸ“¦ Ã‰tape 5 : DÃ©ployer

### 1. ArrÃªter les conteneurs actuels

```bash
cd /srv/dev-disk-by-uuid-8a747308-0fd1-4223-b1be-09ccfdf4bad1/sources/mo5-rag-server/deployment/pi-nas
sudo docker-compose down
```

### 2. Reconstruire l'image avec Python

```bash
sudo docker-compose build --no-cache
```

**âš ï¸ Attention** : La premiÃ¨re construction sera **longue** (~10-20 minutes) car :
- Installation de Python dans le conteneur
- TÃ©lÃ©chargement du modÃ¨le (~420 MB)
- Installation des dÃ©pendances Python

### 3. DÃ©marrer les conteneurs

```bash
sudo docker-compose up -d
```

### 4. VÃ©rifier les logs

```bash
# Voir les logs en temps rÃ©el
sudo docker-compose logs -f api

# Vous devriez voir :
# [INFO] Initializing Local Embedding Service with model: paraphrase-multilingual-MiniLM-L12-v2
# [INFO] Python is available
# [INFO] Installing Python package: sentence-transformers
# [INFO] Installing Python package: torch
# [INFO] Installing Python package: numpy
# [INFO] Local Embedding Service initialized successfully
```

---

## âœ… Ã‰tape 6 : Tester

### Test 1 : VÃ©rifier le health check

```bash
curl http://localhost:8080/health
```

**RÃ©sultat attendu** : `{"status":"Healthy"}`

### Test 2 : Faire une recherche

```bash
curl "http://localhost:8080/api/search?q=registre%20accumulateur&maxResults=3"
```

**RÃ©sultat attendu** : JSON avec des rÃ©sultats de recherche

### Test 3 : Comparer avec TF-IDF

Pour voir la diffÃ©rence, vous pouvez comparer les rÃ©sultats :

**Avec TF-IDF** (ancien) :
- Recherche par mots-clÃ©s exacts
- "registre A" trouve uniquement les docs avec "registre" ET "A"

**Avec Sentence Transformers** (nouveau) :
- Recherche sÃ©mantique
- "registre A" trouve aussi "accumulateur", "registre principal", etc.

---

## ğŸ”„ Retour Ã  TF-IDF (si besoin)

Si vous voulez revenir Ã  TF-IDF (plus rapide, moins de ressources) :

### 1. Modifier docker-compose.yml

```yaml
environment:
  - EmbeddingService__Provider=TfIdf  # Changer Local â†’ TfIdf
```

### 2. RedÃ©marrer

```bash
sudo docker-compose down
sudo docker-compose up -d
```

**Pas besoin de reconstruire l'image !**

---

## ğŸ“Š Comparaison des performances

### TF-IDF (actuel)

```
Temps de gÃ©nÃ©ration d'embedding : ~5 ms
MÃ©moire utilisÃ©e : ~50 MB
Espace disque : 0 MB (aucune dÃ©pendance)
QualitÃ© : â­â­â­ (bonne pour termes techniques)
```

### Sentence Transformers (nouveau)

```
Temps de gÃ©nÃ©ration d'embedding : ~50-100 ms
MÃ©moire utilisÃ©e : ~200-300 MB
Espace disque : ~500 MB (modÃ¨le + dÃ©pendances)
QualitÃ© : â­â­â­â­â­ (excellente pour recherche sÃ©mantique)
```

**Sur Raspberry Pi 4 (4 GB RAM)** : Aucun problÃ¨me, largement suffisant ! ğŸš€

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : "Python is not available"

**Cause** : Python n'est pas installÃ© dans le conteneur.

**Solution** : Utilisez le nouveau Dockerfile avec Python (voir Ã©tape 4).

### ProblÃ¨me : "Failed to install sentence-transformers"

**Cause** : Pas assez d'espace disque ou problÃ¨me rÃ©seau.

**Solution** :

```bash
# VÃ©rifier l'espace disque
df -h

# Nettoyer les images Docker inutilisÃ©es
sudo docker system prune -a
```

### ProblÃ¨me : "Model download timeout"

**Cause** : Le tÃ©lÃ©chargement du modÃ¨le (~420 MB) prend du temps.

**Solution** : Augmenter le timeout dans docker-compose.yml :

```yaml
healthcheck:
  start_period: 120s  # Au lieu de 40s
```

### ProblÃ¨me : Conteneur redÃ©marre en boucle

**Cause** : Erreur au dÃ©marrage (Python, modÃ¨le, etc.).

**Solution** : Voir les logs :

```bash
sudo docker-compose logs api
```

### ProblÃ¨me : Recherche trÃ¨s lente

**Cause** : Le Raspberry Pi gÃ©nÃ¨re les embeddings Ã  la demande.

**Solution** : C'est normal pour la premiÃ¨re recherche (tÃ©lÃ©chargement du modÃ¨le). Les suivantes sont plus rapides (modÃ¨le en cache).

---

## ğŸ’¡ Optimisations possibles

### 1. PrÃ©-tÃ©lÃ©charger le modÃ¨le

Au lieu de tÃ©lÃ©charger le modÃ¨le au premier dÃ©marrage, vous pouvez le prÃ©-tÃ©lÃ©charger :

```bash
# Sur le Raspberry Pi
python3 -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
```

### 2. Utiliser un volume pour le cache du modÃ¨le

Ajouter dans docker-compose.yml :

```yaml
volumes:
  - ../../knowledge:/app/knowledge:ro
  - ~/.cache/huggingface:/root/.cache/huggingface  # Cache du modÃ¨le
```

**Avantage** : Le modÃ¨le n'est tÃ©lÃ©chargÃ© qu'une seule fois, mÃªme si vous reconstruisez l'image.

### 3. Ajuster le MinSimilarityScore

Avec Sentence Transformers, vous pouvez baisser le seuil :

```yaml
environment:
  - RagSettings__MinSimilarityScore=0.5  # Au lieu de 0.7
```

**Raison** : Le modÃ¨le neuronal donne des scores plus nuancÃ©s.

---

## ğŸ“ RÃ©sumÃ© des Ã©tapes

1. âœ… **Installer Python 3.8+** sur le Raspberry Pi
2. âœ… **CrÃ©er un nouveau Dockerfile** avec Python (je vais le faire)
3. âœ… **Modifier docker-compose.yml** : `Provider=Local`
4. âœ… **Reconstruire et dÃ©ployer** : `docker-compose build && docker-compose up -d`
5. âœ… **VÃ©rifier les logs** : `docker-compose logs -f api`
6. âœ… **Tester** : `curl http://localhost:8080/api/search?q=test`

---

## ğŸ¯ Prochaines Ã©tapes

Voulez-vous que je :

1. **CrÃ©e le nouveau Dockerfile** avec Python inclus ?
2. **Modifie docker-compose.yml** pour activer le modÃ¨le neuronal ?
3. **CrÃ©e un script de dÃ©ploiement** automatique ?

Dites-moi ce que vous prÃ©fÃ©rez ! ğŸ˜Š
- TÃ©lÃ©chargement du modÃ¨le (~420 MB)
- Installation des dÃ©pendances Python

### 3. DÃ©marrer les conteneurs

```bash
sudo docker-compose up -d
```

### 4. VÃ©rifier les logs

```bash
# Voir les logs en temps rÃ©el
sudo docker-compose logs -f api

# Vous devriez voir :
# [INFO] Initializing Local Embedding Service with model: paraphrase-multilingual-MiniLM-L12-v2
# [INFO] Python is available
# [INFO] Installing Python package: sentence-transformers
# [INFO] Installing Python package: torch
# [INFO] Installing Python package: numpy
# [INFO] Local Embedding Service initialized successfully
```

---

## âœ… Ã‰tape 6 : Tester

### Test 1 : VÃ©rifier le health check

```bash
curl http://localhost:8080/health
```

**RÃ©sultat attendu** : `{"status":"Healthy"}`

### Test 2 : Faire une recherche

```bash
curl "http://localhost:8080/api/search?q=registre%20accumulateur&maxResults=3"
```

**RÃ©sultat attendu** : JSON avec des rÃ©sultats de recherche


